{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess\n",
    "利用RNN來預測ICLR文章被接受與否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary： 2540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'': 62,\n",
       " 'synthesizing': 823,\n",
       " 'interpretability': 1291,\n",
       " 'sgd': 635,\n",
       " 'gates': 1437,\n",
       " 'notion': 1580,\n",
       " 'distilling': 1668,\n",
       " 'teachers': 1596,\n",
       " 'differentially': 314,\n",
       " 'matrix': 212,\n",
       " 'm': 1097,\n",
       " 'beam': 2339,\n",
       " 'margin': 644,\n",
       " 'spatio-temporal': 2457,\n",
       " 'apprentice:': 292,\n",
       " 'rectified': 611,\n",
       " 'multi-modal,': 233,\n",
       " 'wavelets': 1624,\n",
       " 'algorithms': 474,\n",
       " 'transaction': 2052,\n",
       " 'the': 75,\n",
       " 'primate': 1029,\n",
       " 'mutual': 2069,\n",
       " 'recasting': 620,\n",
       " 'cramer': 1957,\n",
       " 'anomaly': 520,\n",
       " 'ambiguous': 1079,\n",
       " 'sql': 1455,\n",
       " 'question': 189,\n",
       " 'resnet': 1750,\n",
       " 'warm': 1232,\n",
       " 'estimation': 15,\n",
       " 'brains': 1545,\n",
       " 'approaches': 1866,\n",
       " 'bandwidth': 340,\n",
       " 'probability': 1557,\n",
       " 'aggregation': 185,\n",
       " 'query,': 1076,\n",
       " 'representing': 1429,\n",
       " 'separable': 513,\n",
       " 'dora': 856,\n",
       " 'resistant': 468,\n",
       " 'residuals': 1251,\n",
       " 'facial': 1655,\n",
       " 'using': 137,\n",
       " 'anytime': 1741,\n",
       " 'base': 1523,\n",
       " 'showdown:': 61,\n",
       " 'compilation-based': 1147,\n",
       " 'rbm': 2393,\n",
       " 'ultra-deep': 1250,\n",
       " 'performs': 885,\n",
       " 'can': 162,\n",
       " 'construction': 1774,\n",
       " 'inference-based': 2138,\n",
       " 'time-frequency': 1831,\n",
       " 'similarity': 1040,\n",
       " 'cnn': 1380,\n",
       " 'trend': 2251,\n",
       " 'graphvae:': 2093,\n",
       " 'systematic': 1602,\n",
       " 'generalizing': 129,\n",
       " 'gram:': 2373,\n",
       " 'gpus': 1391,\n",
       " '2-bit/weight': 2202,\n",
       " 'integrating': 1585,\n",
       " 'hyperprior': 276,\n",
       " 'equilibrium:': 650,\n",
       " 'federated': 1632,\n",
       " 'calls': 791,\n",
       " 'pedestrian': 2507,\n",
       " 'symmetry-breaking': 1386,\n",
       " 'graphics': 2035,\n",
       " 'radial': 1533,\n",
       " 'applications': 1770,\n",
       " 'skip': 426,\n",
       " 'matching': 435,\n",
       " 'universal': 447,\n",
       " 'contrasting': 2534,\n",
       " 'system-call': 2464,\n",
       " 'egocentric': 2041,\n",
       " 'resist': 405,\n",
       " 'catastrophic': 896,\n",
       " 'sparse-complementary': 1701,\n",
       " 'orthogonality': 2227,\n",
       " 'beta-vae:': 1217,\n",
       " 'ganglion': 1030,\n",
       " 'diffusing': 2171,\n",
       " 'outrageously': 1168,\n",
       " 'translation': 239,\n",
       " 'data': 54,\n",
       " 'assessment': 1745,\n",
       " 'smoothing': 1110,\n",
       " 'parallelizing': 507,\n",
       " 'trick': 523,\n",
       " 'log-densenet:': 1698,\n",
       " '(isrlus)': 1645,\n",
       " 'micromanagement': 1071,\n",
       " 'on': 74,\n",
       " 'activities': 2321,\n",
       " 'phrase-based': 487,\n",
       " 'encoding': 1507,\n",
       " 'jack-of-all-trades:': 2382,\n",
       " 'data;': 2048,\n",
       " '$k$-class': 1481,\n",
       " 'guarantees': 2160,\n",
       " 'block-diagonal': 1850,\n",
       " 'scene': 1335,\n",
       " 'jackknife': 802,\n",
       " 'pact:': 2148,\n",
       " 'sensitive': 1792,\n",
       " 'counterpoint': 2314,\n",
       " 'consequentialist': 695,\n",
       " 'lens': 2402,\n",
       " 'mmd': 252,\n",
       " 'a': 28,\n",
       " 'controlling': 2070,\n",
       " 'song': 1365,\n",
       " 'transport': 12,\n",
       " 'latent-variable': 1574,\n",
       " 'motivated': 51,\n",
       " 'speed-up': 2116,\n",
       " 'target': 2177,\n",
       " 'starcraft': 1070,\n",
       " 'atari': 2141,\n",
       " 'pruning': 218,\n",
       " 'behavior': 954,\n",
       " 'difficulties': 126,\n",
       " 'bit-regularized': 1861,\n",
       " 'taming': 2296,\n",
       " 'that': 638,\n",
       " 'reduction': 977,\n",
       " 'but': 1130,\n",
       " 'musically': 1367,\n",
       " 'manifolds': 1305,\n",
       " 'nested': 2477,\n",
       " 'zoneout:': 1158,\n",
       " 'lower': 1856,\n",
       " 'human-computer': 1874,\n",
       " 'hadamard': 1328,\n",
       " 'responses': 1032,\n",
       " 'sisyphean': 2489,\n",
       " 'useful': 1839,\n",
       " 'mix': 2125,\n",
       " 'communication': 232,\n",
       " ':': 1611,\n",
       " 'entropy': 530,\n",
       " 'remo': 1518,\n",
       " 'tumor': 1949,\n",
       " 'perform': 576,\n",
       " 'updates': 429,\n",
       " 'your': 912,\n",
       " 'expressive': 538,\n",
       " 'taxonomy': 1728,\n",
       " 'sequential': 840,\n",
       " 'again': 1915,\n",
       " 'chit-chat:': 1776,\n",
       " 'interactions': 557,\n",
       " 'space-by-time': 1780,\n",
       " 'answer:': 746,\n",
       " 'comparison': 64,\n",
       " 'images': 423,\n",
       " 'two-layer': 1987,\n",
       " 'dynamically': 751,\n",
       " 'traffic': 548,\n",
       " 'automata': 2183,\n",
       " 'chunkwise': 619,\n",
       " 'concorde': 1459,\n",
       " 'vectors': 1289,\n",
       " 'news': 1462,\n",
       " 'binary': 96,\n",
       " 'summarization': 332,\n",
       " 'control': 272,\n",
       " 'how': 780,\n",
       " 'power': 364,\n",
       " 'shannon': 2062,\n",
       " 'rates': 1859,\n",
       " 'large-batch': 999,\n",
       " 'gurantees': 1882,\n",
       " 'reliable': 375,\n",
       " 'correcting': 1904,\n",
       " 'k-shot': 2076,\n",
       " 'transformation-based': 2303,\n",
       " 'independent': 1810,\n",
       " 'points': 352,\n",
       " 'objective': 383,\n",
       " 'feat2vec:': 1902,\n",
       " 'spectrally-normalized': 643,\n",
       " 'recognition': 304,\n",
       " 'postprocessing': 675,\n",
       " 'homologically': 2397,\n",
       " 'retrieval-based': 1872,\n",
       " 'ai': 2238,\n",
       " 'optimism': 922,\n",
       " 'ganite:': 396,\n",
       " 'annealing': 2390,\n",
       " 'sequence': 437,\n",
       " 'structures': 737,\n",
       " 'boltzmann': 1576,\n",
       " 'explanations': 2026,\n",
       " 'multi-layered': 1968,\n",
       " 'views': 2235,\n",
       " 'distinct': 2077,\n",
       " 'session-based': 1989,\n",
       " 'double': 1684,\n",
       " 'introspection:accelerating': 1172,\n",
       " 'directing': 1538,\n",
       " 'testing': 2195,\n",
       " 'minimal-entropy': 1,\n",
       " 'ups:': 1686,\n",
       " 'diverse': 1711,\n",
       " 'association': 662,\n",
       " 'comparative': 1603,\n",
       " 'bidirectional': 551,\n",
       " 'optimality': 775,\n",
       " 'results': 2091,\n",
       " 'operators': 1819,\n",
       " 'relevance': 1793,\n",
       " 'locomotion': 2520,\n",
       " '(un)reliability': 2023,\n",
       " 'shared': 170,\n",
       " 'verification:': 1889,\n",
       " 'tasks': 450,\n",
       " 'guarding': 2016,\n",
       " 'multi-advisor': 2137,\n",
       " 'seeking': 804,\n",
       " 'combinatorial': 1653,\n",
       " 'attacks': 376,\n",
       " 'style': 1327,\n",
       " 'does': 1044,\n",
       " 'dynamical': 485,\n",
       " 'learners)': 2352,\n",
       " 'feed-forward': 1717,\n",
       " 'error': 1506,\n",
       " 'trust-region': 26,\n",
       " 'segmentation': 1503,\n",
       " 'via': 152,\n",
       " 'parameterization': 1846,\n",
       " 'color': 1775,\n",
       " 'multivariate': 2282,\n",
       " 'slot': 2139,\n",
       " 'leap:': 1529,\n",
       " 'controllers': 2319,\n",
       " 'robotics': 1419,\n",
       " 'listening': 1381,\n",
       " 'interpolation': 68,\n",
       " 'full-network': 1773,\n",
       " 'dilated': 969,\n",
       " 'background': 1848,\n",
       " 'interact': 1795,\n",
       " 'paraphrases': 2512,\n",
       " 'neuron': 2443,\n",
       " 'pay': 617,\n",
       " 'fat': 1085,\n",
       " 'attacking': 510,\n",
       " 'cloze': 1593,\n",
       " 'gating': 1129,\n",
       " 'defenses': 499,\n",
       " 'safe': 693,\n",
       " 'music': 1190,\n",
       " 'metacontrol': 1154,\n",
       " 'riemannian': 2414,\n",
       " 'pixelcnn++:': 1053,\n",
       " 'processes:': 470,\n",
       " 'protecting': 501,\n",
       " 'process': 478,\n",
       " 'battle': 2132,\n",
       " 'survival': 1548,\n",
       " 'goal': 48,\n",
       " 'regularization': 249,\n",
       " 'size': 627,\n",
       " 'states': 2122,\n",
       " 'data-driven': 547,\n",
       " 'alone': 1610,\n",
       " 'larger': 1857,\n",
       " 'action-dependent': 271,\n",
       " 'life': 2228,\n",
       " 'identification': 1951,\n",
       " 'dense': 935,\n",
       " 'multi-scale': 934,\n",
       " 'algorithm': 165,\n",
       " 'model:': 1884,\n",
       " 'medical': 1927,\n",
       " 'masks': 2440,\n",
       " 'product': 1329,\n",
       " 'deep': 6,\n",
       " 'same': 1188,\n",
       " 'supervision:': 2481,\n",
       " 'bi-directional': 593,\n",
       " 'lipnet:': 2408,\n",
       " 'for?': 1840,\n",
       " 'connections': 451,\n",
       " 'properties': 357,\n",
       " 'self-attention': 345,\n",
       " 'analytical': 355,\n",
       " 'em': 711,\n",
       " 'sparsify': 1699,\n",
       " 'asr': 1827,\n",
       " 'atm': 2058,\n",
       " 'machine': 123,\n",
       " 'world': 444,\n",
       " 'global-local': 203,\n",
       " 'q-learning': 1228,\n",
       " 'host-based': 2465,\n",
       " 'bound:': 2010,\n",
       " 'towards': 413,\n",
       " 'diversity': 128,\n",
       " 'discriminative': 1822,\n",
       " 'explanation': 2014,\n",
       " 'alexnet-level': 2468,\n",
       " 'approximations': 629,\n",
       " 'explain': 781,\n",
       " 'embarrassingly': 1480,\n",
       " 'object': 1512,\n",
       " 'enhancing': 108,\n",
       " 'environment': 433,\n",
       " 'overlapping': 539,\n",
       " 'bonus': 2147,\n",
       " 'ucb': 2120,\n",
       " 'remember!': 1648,\n",
       " 'reliability': 109,\n",
       " 'pedagogical': 2003,\n",
       " 'insights': 2461,\n",
       " 'forth': 1350,\n",
       " 'semi-parametric': 455,\n",
       " 'backprop': 1556,\n",
       " 'localization': 578,\n",
       " 'maximum': 166,\n",
       " 'contexts': 2407,\n",
       " 'shift': 1348,\n",
       " 'transformation': 1597,\n",
       " 'expression': 2168,\n",
       " 'response': 579,\n",
       " 'automated': 1345,\n",
       " '“style”': 1829,\n",
       " 'competing': 1940,\n",
       " 'high-capacity': 1554,\n",
       " 'reducing': 339,\n",
       " 'arena': 2133,\n",
       " 'dialogue': 1244,\n",
       " 'signal': 1993,\n",
       " 'augmentation': 1392,\n",
       " 'weights': 521,\n",
       " 'integration': 1847,\n",
       " 'first-person': 1099,\n",
       " 'avoiding': 1841,\n",
       " 'conductor': 1967,\n",
       " 'applied': 2515,\n",
       " 'rethinking': 541,\n",
       " 'learn': 564,\n",
       " 'mappings': 552,\n",
       " 'bloom': 2506,\n",
       " 'select': 1981,\n",
       " 'incremental': 605,\n",
       " 'intelligible': 2252,\n",
       " 'approximation': 289,\n",
       " 'codes': 1303,\n",
       " 'parametrizing': 1837,\n",
       " 'clustering': 244,\n",
       " 'perception': 1041,\n",
       " 'normalizing': 1024,\n",
       " 'one-hidden-layer': 348,\n",
       " 'approach': 85,\n",
       " 'over': 508,\n",
       " 'discovering': 1332,\n",
       " 'q-distribution': 2144,\n",
       " 'multiscale': 1321,\n",
       " 'closed-loop': 359,\n",
       " 'dnns': 2301,\n",
       " 'network': 297,\n",
       " 'test': 1594,\n",
       " 'quality,': 973,\n",
       " 'leave': 689,\n",
       " 'questions': 1078,\n",
       " 'texts': 1080,\n",
       " 'character-aware': 2236,\n",
       " 'evaluate': 1337,\n",
       " 'plasticity': 1805,\n",
       " 'significance': 2528,\n",
       " 'identifying': 570,\n",
       " 'hexaconv': 467,\n",
       " 'auction': 2029,\n",
       " 'ubuntu': 1789,\n",
       " 'arbitrary': 1903,\n",
       " 'encoder-decoder': 1691,\n",
       " 'compressing': 333,\n",
       " 'conceptor-aided': 898,\n",
       " 'point:': 2290,\n",
       " 'content': 1102,\n",
       " 'sets:': 1637,\n",
       " 'semi-supervised': 586,\n",
       " 'particle': 1568,\n",
       " 'predicting': 229,\n",
       " 'walks': 1435,\n",
       " 'case': 2482,\n",
       " 'softmax-based': 2529,\n",
       " 'attentive': 817,\n",
       " 'lsd-net:': 2038,\n",
       " 'hyperspectral': 1935,\n",
       " 'epitomic': 2275,\n",
       " 'diagnostic': 1302,\n",
       " 'compression': 223,\n",
       " 'trainability': 1134,\n",
       " 'solution,': 1769,\n",
       " 'respresentations': 1516,\n",
       " 'attention:': 1013,\n",
       " 'irregularly': 1753,\n",
       " 'error-correcting': 2419,\n",
       " 'disentangling': 448,\n",
       " 'fine-tuning': 683,\n",
       " 'planar': 1299,\n",
       " 'decorrelations': 1203,\n",
       " 'privacy': 2013,\n",
       " 'cycada:': 2074,\n",
       " 'memorization': 385,\n",
       " 'coattention': 670,\n",
       " 'analytics': 2266,\n",
       " 'analysis': 369,\n",
       " 'hyperband:': 1174,\n",
       " 'vehicle': 1898,\n",
       " 'transferability': 1705,\n",
       " 'multi-task': 600,\n",
       " 'manifold': 1679,\n",
       " 'sqlnet:': 1448,\n",
       " 'model': 266,\n",
       " 'cracking': 480,\n",
       " 'affect': 1791,\n",
       " 'meta-optimization': 812,\n",
       " 'trusting': 1194,\n",
       " 'interpreting': 1478,\n",
       " 'interactive': 440,\n",
       " 'performance': 1014,\n",
       " 'complexity': 445,\n",
       " 'coevolutionary': 2305,\n",
       " 'sets': 1361,\n",
       " 'texture': 1151,\n",
       " 'debiasing': 798,\n",
       " 'guide': 876,\n",
       " 'converges': 887,\n",
       " 'encoder-decoders': 2431,\n",
       " 'input': 424,\n",
       " 'bias': 647,\n",
       " 'dsd:': 1119,\n",
       " 'backward': 2129,\n",
       " 'fashion': 2244,\n",
       " 'primal-dual': 714,\n",
       " 'geometric': 891,\n",
       " 'enforcing': 2494,\n",
       " 'deductive': 180,\n",
       " 'many-task': 2263,\n",
       " 'reasoning': 747,\n",
       " 'distillation,': 1972,\n",
       " 'fearnet:': 603,\n",
       " 'lsh': 2064,\n",
       " 'convnet': 2354,\n",
       " 'wavelet': 601,\n",
       " 'middle': 2421,\n",
       " 'textures?': 1047,\n",
       " 'penalizing': 2375,\n",
       " 'real-time': 182,\n",
       " 'logit': 2153,\n",
       " 'sympathetic': 2022,\n",
       " 'time-series': 2458,\n",
       " 'evidence': 184,\n",
       " 'short': 1211,\n",
       " 'datasets': 1428,\n",
       " 'lossless': 1270,\n",
       " 'novel': 1042,\n",
       " 'neurogenesis-inspired': 2335,\n",
       " 'matters': 1282,\n",
       " 'deepcoder:': 1240,\n",
       " 'wasserstein': 713,\n",
       " 'floor-level': 789,\n",
       " 'ratings': 2313,\n",
       " 'privileged': 2509,\n",
       " 'robustness,': 1681,\n",
       " 'nonparametric': 1018,\n",
       " 'physics': 1135,\n",
       " 'gans:': 720,\n",
       " 'problem,': 1768,\n",
       " 'knowledge': 293,\n",
       " 'pruning,': 1973,\n",
       " 'dropout': 250,\n",
       " 'alternating': 870,\n",
       " 'speech': 1385,\n",
       " 'diagnose': 1919,\n",
       " 'hierarchies:': 758,\n",
       " 'two-layered': 1388,\n",
       " 'troubleshooting': 2072,\n",
       " 'displaced': 1600,\n",
       " 'functions,': 2478,\n",
       " 'proposed': 528,\n",
       " 'score': 1660,\n",
       " 'classifiers': 306,\n",
       " 'directed': 858,\n",
       " 'maintaining': 1897,\n",
       " 'soft': 760,\n",
       " 'proof': 1628,\n",
       " 'nlp': 2264,\n",
       " 'summaries': 1879,\n",
       " 'sample': 1276,\n",
       " 'cooperative': 1895,\n",
       " 'gradient': 160,\n",
       " 'variation': 975,\n",
       " 'ive-gan:': 1812,\n",
       " 'spike-based': 2098,\n",
       " 'rate,': 624,\n",
       " 'lead': 1312,\n",
       " 'examination': 2383,\n",
       " 'priority': 1489,\n",
       " 'perspective': 659,\n",
       " '3:': 845,\n",
       " 'baseline': 1132,\n",
       " 'canonical': 2245,\n",
       " 'paragram': 2089,\n",
       " 'medications': 1301,\n",
       " '#exploration:': 2225,\n",
       " 'rnns': 202,\n",
       " 'provably': 639,\n",
       " 'an': 42,\n",
       " '1,': 1095,\n",
       " 'every': 656,\n",
       " 'determinantal': 2103,\n",
       " 'static': 2497,\n",
       " 'hyperedge2vec:': 2213,\n",
       " 'large-scale': 1592,\n",
       " 'feature': 1034,\n",
       " 'applying': 1721,\n",
       " 'samplernn:': 1152,\n",
       " 'network-based': 1786,\n",
       " 'spherical': 940,\n",
       " 'divide': 155,\n",
       " 'visual': 79,\n",
       " 'degradation': 1842,\n",
       " 'samples': 308,\n",
       " 'slow': 2418,\n",
       " 'geometry': 291,\n",
       " 'universality': 825,\n",
       " 'ddrprog:': 1886,\n",
       " 'void:': 796,\n",
       " 'introspective': 1324,\n",
       " 'expressing': 366,\n",
       " 'decisions:': 1224,\n",
       " 'online': 133,\n",
       " 'randomization': 707,\n",
       " 'pseudo-independent': 282,\n",
       " 'simulating': 475,\n",
       " 'matters:': 492,\n",
       " 'non-parametric': 1573,\n",
       " 'realtime': 1496,\n",
       " 'increase': 625,\n",
       " 'convolution': 343,\n",
       " 'grained': 1258,\n",
       " 'kernel': 286,\n",
       " 'rationales': 1929,\n",
       " 'license': 2031,\n",
       " 'trenet:': 2250,\n",
       " 'update': 2130,\n",
       " 'support': 1287,\n",
       " 'domain-invariant': 1268,\n",
       " 'vanishing': 1718,\n",
       " 'frustratingly': 1210,\n",
       " 'passthrough': 2276,\n",
       " 'is': 879,\n",
       " 'inversion': 1808,\n",
       " 'tuning': 1400,\n",
       " 'robot': 46,\n",
       " 'message': 269,\n",
       " 'charged': 1422,\n",
       " 'go': 743,\n",
       " 'boundary': 709,\n",
       " 'low': 2502,\n",
       " 'optimization': 27,\n",
       " 'proving': 1318,\n",
       " 'policy': 18,\n",
       " 'similarities': 1463,\n",
       " 'characters?': 1127,\n",
       " 'epopt:': 1182,\n",
       " 'jiffy:': 1465,\n",
       " 'sentences': 1280,\n",
       " 'inner': 1636,\n",
       " 'residual': 105,\n",
       " 'evasion': 2302,\n",
       " 'cnns': 941,\n",
       " 'steganography': 2367,\n",
       " 'curricula': 686,\n",
       " 'weather': 2272,\n",
       " 'tying': 264,\n",
       " 'basic': 1218,\n",
       " 'free': 1098,\n",
       " 'half-rectified': 1010,\n",
       " 'reading': 346,\n",
       " 'distance': 1906,\n",
       " 'limits': 2136,\n",
       " 'extended': 99,\n",
       " 'entitites': 1615,\n",
       " 'gpu': 1238,\n",
       " 'building': 1561,\n",
       " 'experience': 300,\n",
       " '$o(kd)$': 1488,\n",
       " 'agent': 200,\n",
       " 'small': 1407,\n",
       " 'musical': 1830,\n",
       " 'fusing': 731,\n",
       " 'questions:': 944,\n",
       " 'generate': 146,\n",
       " 'abstraction': 829,\n",
       " 'packet': 1896,\n",
       " 'trajectories': 2135,\n",
       " 'play': 1261,\n",
       " 'hierarchical': 208,\n",
       " 'descriptor': 2325,\n",
       " 'fidelity': 2503,\n",
       " 'robustness': 463,\n",
       " 'readers': 2287,\n",
       " 'lstm-based': 2463,\n",
       " 'meta-learner': 818,\n",
       " 'tough-to-beat': 1131,\n",
       " 'sign': 2172,\n",
       " 'sentiment': 1525,\n",
       " 'simulated+unsupervised': 549,\n",
       " 'nonlinearities': 2347,\n",
       " 'convolutions:': 2329,\n",
       " 'between-class': 302,\n",
       " 'domains': 573,\n",
       " 'clevr': 1887,\n",
       " 'baseline-corrected': 1779,\n",
       " 'competition': 446,\n",
       " 'structural': 1625,\n",
       " 'conditionally': 147,\n",
       " 'bandit-based': 1175,\n",
       " 'kronecker-factored': 628,\n",
       " 'factor': 2518,\n",
       " 'web': 764,\n",
       " 'pretraining': 2433,\n",
       " 'contraction': 2079,\n",
       " 'human': 101,\n",
       " 'waves:': 2297,\n",
       " 'negative': 2416,\n",
       " 'modifying': 1693,\n",
       " 'genomic': 1909,\n",
       " 'equations': 1421,\n",
       " '911': 790,\n",
       " 'modeling': 596,\n",
       " 'input-output': 824,\n",
       " 'bandit': 36,\n",
       " 'yet': 2411,\n",
       " 'explaining': 2020,\n",
       " 'unlabeled': 279,\n",
       " 'emerge': 2480,\n",
       " 'sensory': 2097,\n",
       " 'coarse': 2439,\n",
       " 'processing': 2220,\n",
       " 'classless': 2446,\n",
       " 'communications': 2524,\n",
       " 'encourage': 452,\n",
       " 'audio': 1153,\n",
       " 'multi-directional': 919,\n",
       " 'holstep:': 1313,\n",
       " 'tic-tac-toe': 2483,\n",
       " 'discrete-continuous': 2134,\n",
       " 'classify': 2423,\n",
       " 'code': 337,\n",
       " 'arithmetic': 1709,\n",
       " 'data-efficient': 1983,\n",
       " 'recovery': 1994,\n",
       " 'induction': 1901,\n",
       " 'random': 1207,\n",
       " 'percolation': 536,\n",
       " 'improving': 135,\n",
       " 'extraction': 1243,\n",
       " 'recursive': 1166,\n",
       " 'relu': 1389,\n",
       " 'hashing': 2398,\n",
       " 'sound': 303,\n",
       " '?': 1734,\n",
       " 'directions': 646,\n",
       " 'post-training': 1836,\n",
       " 'invariance': 2248,\n",
       " 'loop': 313,\n",
       " 'neurodegenerative': 1933,\n",
       " 'weakly-supervised': 1925,\n",
       " 'lipschitz': 2157,\n",
       " 'weight-width': 1621,\n",
       " 'auto-conditioned': 97,\n",
       " 'leveraging': 86,\n",
       " 'visually': 558,\n",
       " 'model-parallel': 1980,\n",
       " 'coulomb': 719,\n",
       " 'biaffine': 1087,\n",
       " 'family:': 2002,\n",
       " 'transfer': 590,\n",
       " 'open': 1777,\n",
       " 'diagonal': 1635,\n",
       " 'time-domain': 1947,\n",
       " 'weighted': 1539,\n",
       " 'trace:': 691,\n",
       " 'curves': 1300,\n",
       " 'importance': 238,\n",
       " 'extended-long': 1883,\n",
       " 'layer-wise': 1854,\n",
       " 'high': 221,\n",
       " '$o(d\\\\log{k})$': 1482,\n",
       " 'hidden': 1161,\n",
       " 'singly-labeled': 924,\n",
       " 'selectivity': 2444,\n",
       " 'yellowfin': 1440,\n",
       " 'strategies': 1633,\n",
       " 'joint': 1570,\n",
       " 'b-gan:': 2230,\n",
       " 'photo': 1322,\n",
       " 'misclassified': 1192,\n",
       " 'neural': 29,\n",
       " 'location': 1950,\n",
       " 'ideas:': 1865,\n",
       " 'ego': 1785,\n",
       " 'domain-specific': 1148,\n",
       " 'adjusting': 1862,\n",
       " 'unconstrained': 2496,\n",
       " 'span': 2436,\n",
       " 'paths': 649,\n",
       " 'invariant': 1038,\n",
       " 'enrichment': 1954,\n",
       " 'rl': 864,\n",
       " 'reset': 692,\n",
       " 'paleo:': 1227,\n",
       " 'one': 402,\n",
       " 'incomplete': 1893,\n",
       " 'gap': 1000,\n",
       " 'spaces': 49,\n",
       " 'mastering': 317,\n",
       " 'relaxation': 1206,\n",
       " 'singularities': 592,\n",
       " 'cycle-consistent': 2075,\n",
       " 'boosted': 2242,\n",
       " 'hybridnet:': 2115,\n",
       " 'recurrent': 98,\n",
       " 'risk': 368,\n",
       " 'trust': 408,\n",
       " 'shakedrop': 2117,\n",
       " 'stein': 274,\n",
       " 'enhance': 1379,\n",
       " 'on-chip': 395,\n",
       " 'optimize': 1107,\n",
       " 'nuisance': 1905,\n",
       " 'trust-pcl:': 406,\n",
       " 'counterfactual': 1817,\n",
       " 'unbiasing': 1591,\n",
       " '50x': 2469,\n",
       " 'extensions': 2267,\n",
       " 'mapping': 14,\n",
       " 'imaging': 1928,\n",
       " 'combinator': 828,\n",
       " 'interference': 897,\n",
       " 'monotonic': 618,\n",
       " 'syntax-directed': 175,\n",
       " 'randomly': 1159,\n",
       " 'high-rank': 965,\n",
       " 'spectral': 84,\n",
       " 'causalgan:': 712,\n",
       " 'two': 2332,\n",
       " 'other': 1058,\n",
       " 'causal': 660,\n",
       " 'secure': 2051,\n",
       " 'continuous-fidelity': 2096,\n",
       " 'metric': 580,\n",
       " 'automatically': 415,\n",
       " 'learn?': 882,\n",
       " 'long-term': 2207,\n",
       " 'central': 1265,\n",
       " 'semantic': 67,\n",
       " 'rendergan:': 1408,\n",
       " 'modular': 430,\n",
       " 'evaluation': 489,\n",
       " 'balancing': 1442,\n",
       " 'memory-efficient': 595,\n",
       " 'sparsified': 2472,\n",
       " 'tagging': 1125,\n",
       " 'lifelong': 750,\n",
       " 'eliminet:': 2083,\n",
       " 'efficient': 90,\n",
       " 'generation:': 387,\n",
       " 'alternative': 1638,\n",
       " 'curve': 1106,\n",
       " 'relu:': 2391,\n",
       " 'risks': 1941,\n",
       " 'accurate': 1664,\n",
       " 'connectivity': 1708,\n",
       " 'shifts': 2017,\n",
       " 'vision': 2046,\n",
       " 'painless': 1665,\n",
       " '--': 1964,\n",
       " 'problems': 533,\n",
       " 'projection': 226,\n",
       " 'structure-based': 1870,\n",
       " 'patterns': 838,\n",
       " 'eligibility': 2223,\n",
       " 'vlsi': 1307,\n",
       " 'unleashing': 1807,\n",
       " 'existing': 947,\n",
       " 'maximization': 718,\n",
       " 'tree-structured': 869,\n",
       " 'units:': 1601,\n",
       " 'dga': 1589,\n",
       " 'implementation': 1308,\n",
       " 'mach:': 1479,\n",
       " 'representations?': 1800,\n",
       " 'combining': 20,\n",
       " 'countering': 422,\n",
       " 'softmax:': 2065,\n",
       " 'reactor:': 196,\n",
       " '(bre)': 531,\n",
       " 'samples:': 1372,\n",
       " 'fusion': 1340,\n",
       " 'mcmc': 1569,\n",
       " 'visualizing': 1223,\n",
       " 'natural': 367,\n",
       " 'evaluating': 462,\n",
       " 'heterogeneous': 2150,\n",
       " 'solvers': 1535,\n",
       " 'dungeon:': 318,\n",
       " 'loss': 254,\n",
       " 'copy': 2324,\n",
       " 'draw': 1371,\n",
       " 'entangled': 1334,\n",
       " 'fully': 1946,\n",
       " 'diseases': 1934,\n",
       " 'svd': 1845,\n",
       " 'meta-learning': 157,\n",
       " 'numerical': 2334,\n",
       " 'fourier': 2387,\n",
       " 'warped': 2328,\n",
       " 'signals': 1550,\n",
       " 'sparsely-connected': 1306,\n",
       " 'decrease': 653,\n",
       " 'odyssey:': 2459,\n",
       " 'composable': 1491,\n",
       " 'effort': 2385,\n",
       " 'adversary': 1433,\n",
       " 'skills': 47,\n",
       " 'ensemble': 502,\n",
       " 'effects': 399,\n",
       " 'weibull': 808,\n",
       " 'autoencoders:': 1571,\n",
       " 'face': 2185,\n",
       " 'phonological': 312,\n",
       " 'two-dimensional': 2087,\n",
       " 'asynchronicity': 2309,\n",
       " 'change': 1567,\n",
       " 'convolutions': 514,\n",
       " 'influence-directed': 2025,\n",
       " 'pixeldefend:': 495,\n",
       " 'defense': 391,\n",
       " 'searnn:': 201,\n",
       " 'precision': 143,\n",
       " 'reinforcement': 21,\n",
       " 'physiologically': 2255,\n",
       " 'channel': 544,\n",
       " 'prioritized': 299,\n",
       " 'quantization': 268,\n",
       " 'against': 377,\n",
       " 'prosthesis': 582,\n",
       " 'snapshot': 1092,\n",
       " 'light': 2234,\n",
       " 'supervision': 58,\n",
       " 'understand:': 2406,\n",
       " '2d': 443,\n",
       " 'practice': 2514,\n",
       " 'patterns:': 1563,\n",
       " 'tightening': 1264,\n",
       " 'share:': 261,\n",
       " 'sentinel': 1309,\n",
       " 'letter-based': 1826,\n",
       " 'integer': 927,\n",
       " 'second-order': 1019,\n",
       " 'multi-mention': 916,\n",
       " 'context-conditional': 2342,\n",
       " 'coordination': 1900,\n",
       " '2600': 2142,\n",
       " 'dense-sparse-dense': 1120,\n",
       " 'phasing': 1843,\n",
       " 'analogies': 571,\n",
       " 'made': 1671,\n",
       " 'goal-oriented': 992,\n",
       " 'set': 1911,\n",
       " 'equilibria': 722,\n",
       " 'denotational': 1876,\n",
       " 'integers': 937,\n",
       " 'games': 363,\n",
       " 'cell': 1031,\n",
       " 'minima': 1002,\n",
       " 'layered': 1165,\n",
       " 'beyond': 757,\n",
       " 'atreec:': 867,\n",
       " 'intention': 2527,\n",
       " 'logic': 1316,\n",
       " 'stop': 2456,\n",
       " 'of?': 1672,\n",
       " 'selection': 598,\n",
       " 'discrete': 481,\n",
       " 'rnns:': 393,\n",
       " 'twin': 434,\n",
       " 'direction-preserving': 1855,\n",
       " 'chirplet': 1377,\n",
       " 'time,': 1486,\n",
       " 'counterfactuals': 2486,\n",
       " 'method': 410,\n",
       " 'skip-graph:': 2381,\n",
       " 'defensive': 2300,\n",
       " 'python': 2491,\n",
       " 'superresolution': 1685,\n",
       " 'convolutional': 92,\n",
       " 'angle': 1727,\n",
       " 'smoothed': 1559,\n",
       " 'unit': 1695,\n",
       " 'smartphone': 792,\n",
       " 'retinal': 581,\n",
       " 'auto-encoders:': 1999,\n",
       " 'pricing': 2054,\n",
       " 'encrypt': 2047,\n",
       " 'analyzing': 853,\n",
       " 'subgradient': 715,\n",
       " 'nervenet:': 243,\n",
       " 'transitions': 1007,\n",
       " 'autostacker:': 1498,\n",
       " 'patternnet': 782,\n",
       " 'guided': 1284,\n",
       " 'square': 1643,\n",
       " 'lstm': 668,\n",
       " 'attend': 1049,\n",
       " 'comparing': 1026,\n",
       " 'agents': 1663,\n",
       " 'theoretical': 1342,\n",
       " 'editing': 1323,\n",
       " 'perspectives': 2401,\n",
       " 'units': 612,\n",
       " 'persistent': 392,\n",
       " 'spatial': 577,\n",
       " 'asymmetric': 687,\n",
       " 'bilingual:': 2330,\n",
       " 'transduction': 2358,\n",
       " 'hints': 2180,\n",
       " 'networks': 41,\n",
       " 'gated': 1338,\n",
       " 'encoding:': 401,\n",
       " 'squeezing': 394,\n",
       " 'art': 488,\n",
       " 'surprisal-driven': 2540,\n",
       " 'acquiring': 2176,\n",
       " 'incredible': 2399,\n",
       " 'query': 681,\n",
       " 'auxiliary': 994,\n",
       " 'observations': 280,\n",
       " 'toward': 1446,\n",
       " 'not': 651,\n",
       " 'deeprl:': 2521,\n",
       " 'utilization': 1702,\n",
       " 'image': 111,\n",
       " 'td:': 852,\n",
       " 'generalization': 442,\n",
       " 'fully-connected': 1111,\n",
       " 'verification': 2186,\n",
       " 'lots': 2327,\n",
       " 'value': 465,\n",
       " 'regularizers': 2107,\n",
       " 'subspaces': 960,\n",
       " 'weight-sharing': 1072,\n",
       " 'polynomial': 2474,\n",
       " 'invertibility': 2380,\n",
       " 'reduced-precision': 193,\n",
       " 'scattering': 534,\n",
       " 'audio-visual': 2429,\n",
       " 'pro-active': 1801,\n",
       " 'pate': 772,\n",
       " 'recollections': 2175,\n",
       " 'paragraph': 2462,\n",
       " 'counting': 439,\n",
       " 'curvature': 76,\n",
       " 'shrinking': 2400,\n",
       " 'speed': 482,\n",
       " 'are': 1838,\n",
       " 'bag-of-n-grams,': 908,\n",
       " 'rnn': 966,\n",
       " 'hyper-parameter': 1443,\n",
       " 'intrinsically': 50,\n",
       " 'warp': 505,\n",
       " 'rule': 1242,\n",
       " 'chunk': 2274,\n",
       " 'smooth': 253,\n",
       " 'social': 698,\n",
       " 'hji': 1356,\n",
       " 'playing': 2131,\n",
       " 'or': 851,\n",
       " 'linear/non-linear': 1955,\n",
       " 'scenes': 1050,\n",
       " 'structured': 178,\n",
       " 'genomics': 1086,\n",
       " 'mnist': 1833,\n",
       " 'length': 509,\n",
       " 'reasonet:': 2278,\n",
       " ...}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "accept = pd.read_excel('ICLR_accepted.xlsx')[0]\n",
    "reject = pd.read_excel('ICLR_rejected.xlsx')[0]\n",
    "\n",
    "vocab = {}\n",
    "for i in range(len(accept)):\n",
    "    sentence = accept[i].lower().split(' ')\n",
    "    accept[i] = sentence\n",
    "    for j in sentence:\n",
    "        if j not in vocab:\n",
    "            vocab[j] = len(vocab)+1\n",
    "\n",
    "for i in range(len(reject)):\n",
    "    sentence = reject[i].lower().split(' ')\n",
    "    reject[i] = sentence\n",
    "    for j in sentence:\n",
    "        if j not in vocab:\n",
    "            vocab[j] = len(vocab)+1\n",
    "\n",
    "print ('Vocabulary：',len(vocab))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用字典編碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                    [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "1                 [9, 10, 11, 12, 13, 14, 15]\n",
      "2    [16, 17, 18, 19, 20, 21, 22, 23, 24, 22]\n",
      "3                            [25, 26, 18, 27]\n",
      "4                    [28, 29, 30, 31, 32, 33]\n",
      "Name: 0, dtype: object\n",
      "0                          [208, 1246, 1247, 260]\n",
      "1         [22, 134, 1425, 334, 335, 74, 75, 1426]\n",
      "2                    [1427, 287, 22, 477, 4, 958]\n",
      "3                 [322, 314, 315, 1428, 137, 136]\n",
      "4    [1429, 1430, 42, 740, 478, 4, 1431, 840, 54]\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(accept):\n",
    "    for h,k in enumerate(j):\n",
    "        accept[i][h] = vocab[k]\n",
    "        \n",
    "for i,j in enumerate(reject):\n",
    "    for h,k in enumerate(j):\n",
    "        reject[i][h] = vocab[k]        \n",
    "        \n",
    "print (accept[:5])\n",
    "print (reject[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after sequence padding： torch.Size([582, 10]) torch.Size([753, 10])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "SEQUENCE_SIZE = 10\n",
    "accept_tensor = pad_sequence([torch.tensor(i) for i in accept], batch_first=True, padding_value=0)\n",
    "accept_tensor = accept_tensor[:,:SEQUENCE_SIZE] # 長度限制在10\n",
    "reject_tensor = pad_sequence([torch.tensor(i) for i in reject], batch_first=True, padding_value=0)\n",
    "reject_tensor = reject_tensor[:,:SEQUENCE_SIZE]\n",
    "\n",
    "print ('Size after sequence padding：',accept_tensor.size(), reject_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1235, 10]) torch.Size([100, 10])\n",
      "torch.Size([1235]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "test_X = torch.cat([accept_tensor[:50], reject_tensor[:50]])\n",
    "test_Y = torch.cat([torch.ones(50), torch.zeros(50)]).type(torch.LongTensor)\n",
    "\n",
    "train_X = torch.cat([accept_tensor[50:], reject_tensor[50:]])\n",
    "train_Y = torch.cat([torch.ones(532), torch.zeros(703)]).type(torch.LongTensor)\n",
    "print (train_X.size(), test_X.size())\n",
    "print (train_Y.size(), test_Y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 256\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_SIZE = 2\n",
    "NUM_LAYERS = 1\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embed = nn.Embedding(len(vocab)+1, EMB_DIM) # vocab長度要加1，因為在padding的時候會多一個元素\"0\"\n",
    "        self.lstm = nn.LSTM(EMB_DIM, HIDDEN_DIM, NUM_LAYERS, batch_first=True)\n",
    "        self.dense = nn.Linear(HIDDEN_DIM, OUTPUT_SIZE) # 攤平輸入dense layer\n",
    "\n",
    "    def forward(self, input_sentence):\n",
    "#         print ('\\nInput：', input_sentence.size())\n",
    "        embedding = self.embed(input_sentence)\n",
    "#         print ('After embedding：', embedding.size())\n",
    "\n",
    "        h0 = torch.zeros(NUM_LAYERS, embedding.size(0), HIDDEN_DIM)\n",
    "        c0 = torch.zeros(NUM_LAYERS, embedding.size(0), HIDDEN_DIM)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(embedding, (h0, c0)) # .view(len(input_sentence), 1, -1)\n",
    "#         print ('LSTM output：', lstm_out.size())\n",
    "        lstm_out = lstm_out[:,-1,:]\n",
    "#         print ('LSTM output[:,-1,:]：', lstm_out.size())\n",
    "        output = self.dense(lstm_out)\n",
    "#         print ('After Dense：', output.size())\n",
    "        \n",
    "#         print (lstm_out.size())\n",
    "#         output = self.dense(lstm_out.view(len(input_sentence), -1))\n",
    "#         print (output.size())\n",
    "        # 不須做softmax，pytorch的cross entropy會自動先softmax\n",
    "        return output\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embed = nn.Embedding(len(vocab)+1, EMB_DIM) \n",
    "        self.rnn = nn.RNN(EMB_DIM, HIDDEN_DIM, NUM_LAYERS, batch_first=True)\n",
    "        self.dense = nn.Linear(HIDDEN_DIM, OUTPUT_SIZE)\n",
    "\n",
    "    def forward(self, input_sentence):\n",
    "\n",
    "        embedding = self.embed(input_sentence)    \n",
    "        rnn_out, _ = self.rnn(embedding)\n",
    "        rnn_out = rnn_out[:,-1,:]\n",
    "\n",
    "        output = self.dense(rnn_out)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train loss: 0.67523 | train accuracy: 0.641 | test accuracy: 0.530\n",
      "Epoch: 1 | train loss: 0.67136 | train accuracy: 0.609 | test accuracy: 0.510\n",
      "Epoch: 2 | train loss: 0.67591 | train accuracy: 0.547 | test accuracy: 0.490\n",
      "Epoch: 2 | train loss: 0.66308 | train accuracy: 0.594 | test accuracy: 0.500\n",
      "Epoch: 3 | train loss: 0.64500 | train accuracy: 0.609 | test accuracy: 0.510\n",
      "Epoch: 3 | train loss: 0.65060 | train accuracy: 0.547 | test accuracy: 0.480\n",
      "Epoch: 4 | train loss: 0.62751 | train accuracy: 0.562 | test accuracy: 0.530\n",
      "Epoch: 4 | train loss: 0.58290 | train accuracy: 0.766 | test accuracy: 0.560\n",
      "Epoch: 5 | train loss: 0.49180 | train accuracy: 0.859 | test accuracy: 0.550\n",
      "Epoch: 5 | train loss: 0.44549 | train accuracy: 0.812 | test accuracy: 0.560\n",
      "Epoch: 6 | train loss: 0.44510 | train accuracy: 0.766 | test accuracy: 0.560\n",
      "Epoch: 6 | train loss: 0.32755 | train accuracy: 0.891 | test accuracy: 0.560\n",
      "Epoch: 7 | train loss: 0.23218 | train accuracy: 0.922 | test accuracy: 0.530\n",
      "Epoch: 7 | train loss: 0.24867 | train accuracy: 0.922 | test accuracy: 0.550\n",
      "Epoch: 8 | train loss: 0.16661 | train accuracy: 0.969 | test accuracy: 0.530\n",
      "Epoch: 8 | train loss: 0.08796 | train accuracy: 0.984 | test accuracy: 0.520\n",
      "Epoch: 9 | train loss: 0.06545 | train accuracy: 0.969 | test accuracy: 0.580\n",
      "Epoch: 9 | train loss: 0.11452 | train accuracy: 0.969 | test accuracy: 0.500\n",
      "Epoch: 10 | train loss: 0.01307 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 10 | train loss: 0.01316 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 11 | train loss: 0.00431 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 11 | train loss: 0.00658 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 12 | train loss: 0.08951 | train accuracy: 0.969 | test accuracy: 0.520\n",
      "Epoch: 12 | train loss: 0.00878 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 13 | train loss: 0.00901 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 13 | train loss: 0.00666 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 14 | train loss: 0.00725 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 14 | train loss: 0.00181 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 15 | train loss: 0.00144 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 15 | train loss: 0.00134 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 16 | train loss: 0.00312 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 16 | train loss: 0.00104 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 17 | train loss: 0.00097 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 17 | train loss: 0.00092 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 18 | train loss: 0.00122 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 18 | train loss: 0.05728 | train accuracy: 0.984 | test accuracy: 0.510\n",
      "Epoch: 19 | train loss: 0.00184 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 19 | train loss: 0.00170 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 20 | train loss: 0.00154 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 20 | train loss: 0.00143 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 21 | train loss: 0.00160 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 21 | train loss: 0.00068 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 22 | train loss: 0.00075 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 22 | train loss: 0.00153 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 23 | train loss: 0.00092 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 23 | train loss: 0.00031 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 24 | train loss: 0.00135 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 24 | train loss: 0.00018 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 25 | train loss: 0.00022 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 25 | train loss: 0.05867 | train accuracy: 0.984 | test accuracy: 0.500\n",
      "Epoch: 26 | train loss: 0.00114 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 26 | train loss: 0.00229 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 27 | train loss: 0.00106 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 27 | train loss: 0.00059 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 28 | train loss: 0.00229 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 28 | train loss: 0.00016 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 29 | train loss: 0.00253 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 29 | train loss: 0.00025 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 30 | train loss: 0.00013 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 30 | train loss: 0.00015 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 31 | train loss: 0.00015 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 31 | train loss: 0.00100 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 32 | train loss: 0.00021 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 32 | train loss: 0.00011 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 33 | train loss: 0.00014 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 33 | train loss: 0.00066 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 34 | train loss: 0.00065 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 34 | train loss: 0.00120 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 35 | train loss: 0.00122 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 35 | train loss: 0.00312 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 36 | train loss: 0.00010 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 36 | train loss: 0.00039 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 37 | train loss: 0.00010 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 37 | train loss: 0.00025 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 38 | train loss: 0.00463 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 38 | train loss: 0.00396 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 39 | train loss: 0.00192 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 39 | train loss: 0.00098 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 40 | train loss: 0.00128 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 40 | train loss: 0.00278 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 41 | train loss: 0.03041 | train accuracy: 0.984 | test accuracy: 0.510\n",
      "Epoch: 41 | train loss: 0.02339 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 42 | train loss: 0.01585 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 42 | train loss: 0.03531 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 43 | train loss: 0.02906 | train accuracy: 0.984 | test accuracy: 0.470\n",
      "Epoch: 43 | train loss: 0.01337 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 44 | train loss: 0.00581 | train accuracy: 1.000 | test accuracy: 0.540\n",
      "Epoch: 44 | train loss: 0.00151 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 45 | train loss: 0.00095 | train accuracy: 1.000 | test accuracy: 0.540\n",
      "Epoch: 45 | train loss: 0.00115 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 46 | train loss: 0.00127 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 46 | train loss: 0.01928 | train accuracy: 0.984 | test accuracy: 0.500\n",
      "Epoch: 47 | train loss: 0.00306 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 47 | train loss: 0.00045 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 48 | train loss: 0.00041 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 48 | train loss: 0.00072 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 49 | train loss: 0.00046 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 49 | train loss: 0.00042 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 50 | train loss: 0.00061 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 50 | train loss: 0.00068 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 51 | train loss: 0.00082 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 51 | train loss: 0.00080 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 52 | train loss: 0.00089 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 52 | train loss: 0.00089 | train accuracy: 1.000 | test accuracy: 0.520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 | train loss: 0.00016 | train accuracy: 1.000 | test accuracy: 0.540\n",
      "Epoch: 53 | train loss: 0.00071 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 54 | train loss: 0.00083 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 54 | train loss: 0.00024 | train accuracy: 1.000 | test accuracy: 0.540\n",
      "Epoch: 55 | train loss: 0.00363 | train accuracy: 1.000 | test accuracy: 0.540\n",
      "Epoch: 55 | train loss: 0.00020 | train accuracy: 1.000 | test accuracy: 0.540\n",
      "Epoch: 56 | train loss: 0.00088 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 56 | train loss: 0.00010 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 57 | train loss: 0.05130 | train accuracy: 0.984 | test accuracy: 0.530\n",
      "Epoch: 57 | train loss: 0.00012 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 58 | train loss: 0.00073 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 58 | train loss: 0.00056 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 59 | train loss: 0.00007 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 59 | train loss: 0.00114 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 60 | train loss: 0.00179 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 60 | train loss: 0.00012 | train accuracy: 1.000 | test accuracy: 0.530\n",
      "Epoch: 61 | train loss: 0.00015 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 61 | train loss: 0.00064 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 62 | train loss: 0.00015 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 62 | train loss: 0.04817 | train accuracy: 0.984 | test accuracy: 0.520\n",
      "Epoch: 63 | train loss: 0.00206 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 63 | train loss: 0.00011 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 64 | train loss: 0.00010 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 64 | train loss: 0.00226 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 65 | train loss: 0.00012 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 65 | train loss: 0.00009 | train accuracy: 1.000 | test accuracy: 0.520\n",
      "Epoch: 66 | train loss: 0.00012 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 66 | train loss: 0.00009 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 67 | train loss: 0.00062 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 67 | train loss: 0.00010 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 68 | train loss: 0.00175 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 68 | train loss: 0.00010 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 69 | train loss: 0.00084 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 69 | train loss: 0.05593 | train accuracy: 0.984 | test accuracy: 0.510\n",
      "Epoch: 70 | train loss: 0.00011 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 70 | train loss: 0.00007 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 71 | train loss: 0.00008 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 71 | train loss: 0.00073 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 72 | train loss: 0.00073 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 72 | train loss: 0.00008 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 73 | train loss: 0.00083 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 73 | train loss: 0.04836 | train accuracy: 0.984 | test accuracy: 0.510\n",
      "Epoch: 74 | train loss: 0.00008 | train accuracy: 1.000 | test accuracy: 0.510\n",
      "Epoch: 74 | train loss: 0.00089 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 75 | train loss: 0.00006 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 75 | train loss: 0.00133 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 76 | train loss: 0.00098 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 76 | train loss: 0.00105 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 77 | train loss: 0.00066 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 77 | train loss: 0.00078 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 78 | train loss: 0.00007 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 78 | train loss: 0.00152 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 79 | train loss: 0.00078 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 79 | train loss: 0.05267 | train accuracy: 0.984 | test accuracy: 0.500\n",
      "Epoch: 80 | train loss: 0.00158 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 80 | train loss: 0.00086 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 81 | train loss: 0.00088 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 81 | train loss: 0.00125 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 82 | train loss: 0.00077 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 82 | train loss: 0.00130 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 83 | train loss: 0.00003 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 83 | train loss: 0.05051 | train accuracy: 0.984 | test accuracy: 0.490\n",
      "Epoch: 84 | train loss: 0.00006 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 84 | train loss: 0.00169 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 85 | train loss: 0.00096 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 85 | train loss: 0.00003 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 86 | train loss: 0.00005 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 86 | train loss: 0.00437 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 87 | train loss: 0.00005 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 87 | train loss: 0.05182 | train accuracy: 0.984 | test accuracy: 0.490\n",
      "Epoch: 88 | train loss: 0.00004 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 88 | train loss: 0.00059 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 89 | train loss: 0.00070 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 89 | train loss: 0.00132 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 90 | train loss: 0.00005 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 90 | train loss: 0.00067 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 91 | train loss: 0.00078 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 91 | train loss: 0.00325 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 92 | train loss: 0.00005 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 92 | train loss: 0.00163 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 93 | train loss: 0.00005 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 93 | train loss: 0.00004 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 94 | train loss: 0.00061 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 94 | train loss: 0.00083 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 95 | train loss: 0.00086 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 95 | train loss: 0.00077 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 96 | train loss: 0.00181 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 96 | train loss: 0.00092 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 97 | train loss: 0.00004 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 97 | train loss: 0.00004 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 98 | train loss: 0.05203 | train accuracy: 0.984 | test accuracy: 0.490\n",
      "Epoch: 98 | train loss: 0.00005 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 99 | train loss: 0.00181 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 99 | train loss: 0.00073 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 100 | train loss: 0.00147 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 100 | train loss: 0.05004 | train accuracy: 0.984 | test accuracy: 0.490\n",
      "Epoch: 101 | train loss: 0.00350 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 101 | train loss: 0.00072 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 102 | train loss: 0.00148 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 102 | train loss: 0.04928 | train accuracy: 0.984 | test accuracy: 0.490\n",
      "Epoch: 103 | train loss: 0.00190 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 103 | train loss: 0.00079 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 104 | train loss: 0.05037 | train accuracy: 0.984 | test accuracy: 0.490\n",
      "Epoch: 104 | train loss: 0.00228 | train accuracy: 1.000 | test accuracy: 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105 | train loss: 0.00003 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 105 | train loss: 0.00077 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 106 | train loss: 0.00086 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 106 | train loss: 0.00139 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 107 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 107 | train loss: 0.00211 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 108 | train loss: 0.00154 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 108 | train loss: 0.00209 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 109 | train loss: 0.00180 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 109 | train loss: 0.00086 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 110 | train loss: 0.00156 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 110 | train loss: 0.00087 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 111 | train loss: 0.00003 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 111 | train loss: 0.00089 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 112 | train loss: 0.00078 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 112 | train loss: 0.00059 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 113 | train loss: 0.05051 | train accuracy: 0.984 | test accuracy: 0.500\n",
      "Epoch: 113 | train loss: 0.00004 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 114 | train loss: 0.04693 | train accuracy: 0.984 | test accuracy: 0.500\n",
      "Epoch: 114 | train loss: 0.00105 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 115 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 115 | train loss: 0.00080 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 116 | train loss: 0.00076 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 116 | train loss: 0.00004 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 117 | train loss: 0.00167 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 117 | train loss: 0.00162 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 118 | train loss: 0.00083 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 118 | train loss: 0.00003 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 119 | train loss: 0.00173 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 119 | train loss: 0.00068 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 120 | train loss: 0.00072 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 120 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 121 | train loss: 0.00251 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 121 | train loss: 0.00082 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 122 | train loss: 0.00078 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 122 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.500\n",
      "Epoch: 123 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 123 | train loss: 0.00137 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 124 | train loss: 0.04772 | train accuracy: 0.984 | test accuracy: 0.490\n",
      "Epoch: 124 | train loss: 0.00003 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 125 | train loss: 0.04747 | train accuracy: 0.984 | test accuracy: 0.490\n",
      "Epoch: 125 | train loss: 0.00003 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 126 | train loss: 0.00075 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 126 | train loss: 0.00072 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 127 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 127 | train loss: 0.00090 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 128 | train loss: 0.00161 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 128 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 129 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 129 | train loss: 0.00261 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 130 | train loss: 0.00169 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 130 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 131 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 131 | train loss: 0.00161 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 132 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 132 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 133 | train loss: 0.00066 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 133 | train loss: 0.00183 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 134 | train loss: 0.00092 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 134 | train loss: 0.00003 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 135 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 135 | train loss: 0.00089 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 136 | train loss: 0.00139 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 136 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 137 | train loss: 0.00068 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 137 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 138 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 138 | train loss: 0.00060 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 139 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 139 | train loss: 0.00084 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 140 | train loss: 0.00086 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 140 | train loss: 0.00136 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 141 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 141 | train loss: 0.00090 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 142 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 142 | train loss: 0.00159 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 143 | train loss: 0.00081 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 143 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 144 | train loss: 0.00121 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 144 | train loss: 0.00197 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 145 | train loss: 0.00079 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 145 | train loss: 0.00087 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 146 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 146 | train loss: 0.00087 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 147 | train loss: 0.00331 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 147 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 148 | train loss: 0.00146 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 148 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 149 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 149 | train loss: 0.05092 | train accuracy: 0.984 | test accuracy: 0.490\n",
      "Epoch: 150 | train loss: 0.00157 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 150 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 151 | train loss: 0.04948 | train accuracy: 0.984 | test accuracy: 0.490\n",
      "Epoch: 151 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 152 | train loss: 0.00087 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 152 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 153 | train loss: 0.00074 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 153 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 154 | train loss: 0.00140 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 154 | train loss: 0.00138 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 155 | train loss: 0.00083 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 155 | train loss: 0.00071 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 156 | train loss: 0.00226 | train accuracy: 1.000 | test accuracy: 0.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156 | train loss: 0.00095 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 157 | train loss: 0.00092 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 157 | train loss: 0.00071 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 158 | train loss: 0.00065 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 158 | train loss: 0.00137 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 159 | train loss: 0.00074 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 159 | train loss: 0.00145 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 160 | train loss: 0.00074 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 160 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 161 | train loss: 0.00199 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 161 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 162 | train loss: 0.00147 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 162 | train loss: 0.00225 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 163 | train loss: 0.00180 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 163 | train loss: 0.00107 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 164 | train loss: 0.00102 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 164 | train loss: 0.00096 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 165 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 165 | train loss: 0.00075 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 166 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 166 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 167 | train loss: 0.04673 | train accuracy: 0.984 | test accuracy: 0.490\n",
      "Epoch: 167 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 168 | train loss: 0.00173 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 168 | train loss: 0.04959 | train accuracy: 0.984 | test accuracy: 0.480\n",
      "Epoch: 169 | train loss: 0.00078 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 169 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 170 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 170 | train loss: 0.00074 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 171 | train loss: 0.00082 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 171 | train loss: 0.00141 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 172 | train loss: 0.00070 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 172 | train loss: 0.04996 | train accuracy: 0.984 | test accuracy: 0.480\n",
      "Epoch: 173 | train loss: 0.00081 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 173 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 174 | train loss: 0.00170 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 174 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 175 | train loss: 0.00080 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 175 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 176 | train loss: 0.00238 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 176 | train loss: 0.00076 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 177 | train loss: 0.00080 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 177 | train loss: 0.05057 | train accuracy: 0.984 | test accuracy: 0.480\n",
      "Epoch: 178 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 178 | train loss: 0.00070 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 179 | train loss: 0.00268 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 179 | train loss: 0.00142 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 180 | train loss: 0.00153 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 180 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 181 | train loss: 0.00002 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 181 | train loss: 0.00218 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 182 | train loss: 0.00167 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 182 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.490\n",
      "Epoch: 183 | train loss: 0.00096 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 183 | train loss: 0.04783 | train accuracy: 0.984 | test accuracy: 0.470\n",
      "Epoch: 184 | train loss: 0.00086 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 184 | train loss: 0.00186 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 185 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 185 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 186 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 186 | train loss: 0.00086 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 187 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 187 | train loss: 0.00070 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 188 | train loss: 0.00149 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 188 | train loss: 0.00161 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 189 | train loss: 0.04774 | train accuracy: 0.984 | test accuracy: 0.470\n",
      "Epoch: 189 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.480\n",
      "Epoch: 190 | train loss: 0.00154 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 190 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 191 | train loss: 0.00064 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 191 | train loss: 0.00076 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 192 | train loss: 0.00316 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 192 | train loss: 0.00089 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 193 | train loss: 0.00167 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 193 | train loss: 0.00185 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 194 | train loss: 0.00083 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 194 | train loss: 0.04953 | train accuracy: 0.984 | test accuracy: 0.460\n",
      "Epoch: 195 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 195 | train loss: 0.00075 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 196 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 196 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 197 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 197 | train loss: 0.00350 | train accuracy: 1.000 | test accuracy: 0.470\n",
      "Epoch: 198 | train loss: 0.00156 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 198 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 199 | train loss: 0.00136 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 199 | train loss: 0.00126 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 200 | train loss: 0.00001 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Epoch: 200 | train loss: 0.00073 | train accuracy: 1.000 | test accuracy: 0.460\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.utils.data as Data\n",
    "\n",
    "EPOCH = 200\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "model = LSTM()\n",
    "# model = RNN()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# 包進data loader\n",
    "torch_dataset = Data.TensorDataset(train_X, train_Y)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      \n",
    "    batch_size=BATCH_SIZE,     \n",
    "    shuffle=True,   \n",
    "    num_workers=2,  \n",
    ")\n",
    "\n",
    "train_loss, train_acc, test_acc = [], [], []\n",
    "for epoch in range(1,EPOCH+1):\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):  \n",
    "        batch_x = batch_x\n",
    "        batch_y = batch_y\n",
    "        output = model(batch_x)              \n",
    "        loss = loss_func(output, batch_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # 把這次step的gradient清空\n",
    "        loss.backward()                 \n",
    "        optimizer.step()                # apply gradient\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            # 紀錄test準確率\n",
    "            test_output = model(test_X)\n",
    "            pred_y = torch.max(test_output, 1)[1]\n",
    "            accuracy_test = torch.sum(pred_y == test_Y).type(torch.FloatTensor) / test_Y.size(0)\n",
    "                        \n",
    "            # 紀錄batch準確率\n",
    "            pred_batch_y = torch.max(output, 1)[1]\n",
    "            accuracy_batch = torch.sum(pred_batch_y == batch_y).type(torch.FloatTensor) / batch_y.size(0)\n",
    "            \n",
    "            print('Epoch:', epoch, '| train loss: %.5f' % loss.data,'| train accuracy: %.3f' % accuracy_batch, '| test accuracy: %.3f' % accuracy_test)\n",
    "            \n",
    "    # 紀錄結果\n",
    "    train_loss.append(loss.data)\n",
    "    train_acc.append(accuracy_batch)            \n",
    "    test_acc.append(accuracy_test)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(train_acc, label='Train')\n",
    "plt.plot(test_acc, label='Test')\n",
    "plt.legend()\n",
    "plt.title('Training Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylim(0,1.05)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.title('Learning Curve')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "y",
   "language": "python",
   "name": "y"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
